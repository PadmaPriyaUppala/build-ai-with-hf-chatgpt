{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70ffbadc-38ff-42bd-b7e6-a9a3ce6923dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#installing libraries\n",
    "\n",
    "!pip install python-dotenv\n",
    "!pip install openai\n",
    "!pip install openai-whisper openai yt-dlp\n",
    "!pip install youtube_dl\n",
    "!pip install youtube_transcript_api\n",
    "!pip install torchaudio\n",
    "!pip install sentencepiece\n",
    "!pip install sacremoses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f0382c-d638-4f81-bc57-adb7f99a9294",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing dependencies\n",
    "\n",
    "import re\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "import torch\n",
    "import torchaudio\n",
    "import openai\n",
    "import textwrap\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81326836-fe76-4a9b-becd-529baff4fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the YouTube video URL\n",
    "youtube_url = \"https://www.youtube.com/watch?v=b9rs8yzpGYk\"\n",
    "\n",
    "# Extract the video ID from the URL using regular expressions\n",
    "match = re.search(r\"v=([A-Za-z0-9_-]+)\", youtube_url)\n",
    "if match:\n",
    "    video_id = match.group(1)\n",
    "else:\n",
    "    raise ValueError(\"Invalid YouTube URL\")\n",
    "\n",
    "# Get the transcript from YouTube\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "\n",
    "# Concatenate the transcript into a single string\n",
    "transcript_text = \"\"\n",
    "for segment in transcript:\n",
    "    transcript_text += segment[\"text\"] + \" \"\n",
    "print(transcript_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d04cb574-df4f-4922-8d19-45b0083125cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"Helsinki-NLP/opus-mt-en-es\"\n",
    "translator = pipeline(\"translation\", model=model_checkpoint)\n",
    "\n",
    "# Define the maximum sequence length\n",
    "max_length = 512\n",
    "\n",
    "# Split the input text into smaller segments\n",
    "segments = [transcript_text[i:i+max_length] for i in range(0, len(transcript_text), max_length)]\n",
    "\n",
    "# Translate each segment and concatenate the results\n",
    "translated_text = \"\"\n",
    "for segment in segments:\n",
    "    result = translator(segment)\n",
    "    translated_text += result[0]['translation_text']\n",
    "\n",
    "print(translated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22eea385-4ef9-4d78-a771-e33732ed4008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline, AutoTokenizer\n",
    "\n",
    "# Instantiate the tokenizer and the summarization pipeline\n",
    "tokenizer = AutoTokenizer.from_pretrained('stevhliu/my_awesome_billsum_model')\n",
    "summarizer = pipeline(\"summarization\", model='stevhliu/my_awesome_billsum_model', tokenizer=tokenizer)\n",
    "\n",
    "# Define chunk size in number of words\n",
    "chunk_size = 200 # you may need to adjust this value depending on the average length of your words\n",
    "\n",
    "# Split the text into chunks\n",
    "words = transcript_text.split()\n",
    "chunks = [' '.join(words[i:i+chunk_size]) for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "# Summarize each chunk\n",
    "summaries = []\n",
    "for chunk in chunks:\n",
    "    # Summarize the chunk\n",
    "    summary = summarizer(chunk, max_length=100, min_length=30, do_sample=False)\n",
    "\n",
    "    # Extract the summary text\n",
    "    summary_text = summary[0]['summary_text']\n",
    "\n",
    "    # Add the summary to our list of summaries\n",
    "    summaries.append(summary_text)\n",
    "\n",
    "# Join the summaries back together into a single summary\n",
    "final_summary = ' '.join(summaries)\n",
    "\n",
    "print(final_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34587720-70c2-4bbb-a58c-e258677e961b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_into_chunks(text, max_chunk_size):\n",
    "    return textwrap.wrap(text, max_chunk_size)\n",
    "\n",
    "openai.api_key = \"provide key here\"\n",
    "max_chunk_size = 4000\n",
    "\n",
    "transcript_chunks = split_text_into_chunks(transcript_text, max_chunk_size)\n",
    "summaries = \"\"\n",
    "\n",
    "for chunk in transcript_chunks:\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-16k\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{chunk}\\n\\nCreate short concise summary\"}\n",
    "        ],\n",
    "        max_tokens=250,\n",
    "        temperature=0.5\n",
    "    )\n",
    "\n",
    "    summaries += response['choices'][0]['message']['content'].strip() + \" \"\n",
    "\n",
    "print(\"Summary:\")\n",
    "print(summaries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934c2273-ac70-47cb-8927-817969994bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "model=\"gpt-3.5-turbo-16k\",\n",
    "messages=[\n",
    "{\"role\": \"system\", \"content\": \"You are a technical instructor.\"},\n",
    "{\"role\": \"user\", \"content\": transcript_text},\n",
    "{\"role\": \"user\", \"content\": \"Generate steps to follow from text.\"},\n",
    "]\n",
    ")\n",
    "\n",
    "# The assistant's reply\n",
    "guide= response['choices'][0]['message']['content']\n",
    "\n",
    "print(\"Steps:\")\n",
    "print(guide)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9961167b-d46d-4621-ac5c-1f540234456c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "model=\"gpt-3.5-turbo-16k\",\n",
    "messages=[\n",
    "{\"role\": \"system\", \"content\": \"You are a helpful assistant that generates questions.\"},\n",
    "{\"role\": \"user\", \"content\": transcript_text},\n",
    "{\"role\": \"user\", \"content\": \"Generate 10 quiz questions based on the text with multiple choices.\"},\n",
    "]\n",
    ")\n",
    "\n",
    "# The assistant's reply\n",
    "quiz_questions = response['choices'][0]['message']['content']\n",
    "\n",
    "print(\"Quiz Questions:\")\n",
    "print(quiz_questions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a555b1-6a19-448d-9328-0d86417b3808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
